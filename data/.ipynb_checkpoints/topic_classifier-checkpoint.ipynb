{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/anaconda3/lib/python3.9/site-packages (2.12.0)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.22.4)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.4.7)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (4.22.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (4.5.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (21.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (23.3.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (16.0.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.2.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.32.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.53.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (58.0.4)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.0.3 in /opt/anaconda3/lib/python3.9/site-packages (from jax>=0.3.15->tensorflow) (0.0.4)\n",
      "Requirement already satisfied: scipy>=1.7 in /opt/anaconda3/lib/python3.9/site-packages (from jax>=0.3.15->tensorflow) (1.7.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.28.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.6.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/anaconda3/lib/python3.9/site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/anaconda3/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/anaconda3/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n",
      "Collecting pytorch\n",
      "  Using cached pytorch-1.0.2.tar.gz (689 bytes)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: pytorch\n",
      "  Building wheel for pytorch (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[6 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/27/xh3tm0h964n5gjzv1brx5vrc0000gn/T/pip-install-juw2wdqd/pytorch_c87e77a8236e4432af4e47b81150a314/setup.py\", line 15, in <module>\n",
      "  \u001b[31m   \u001b[0m     raise Exception(message)\n",
      "  \u001b[31m   \u001b[0m Exception: You tried to install \"pytorch\". The package named for PyTorch is \"torch\"\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for pytorch\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for pytorch\n",
      "Failed to build pytorch\n",
      "Installing collected packages: pytorch\n",
      "  Running setup.py install for pytorch ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mRunning setup.py install for pytorch\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[6 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/27/xh3tm0h964n5gjzv1brx5vrc0000gn/T/pip-install-juw2wdqd/pytorch_c87e77a8236e4432af4e47b81150a314/setup.py\", line 11, in <module>\n",
      "  \u001b[31m   \u001b[0m     raise Exception(message)\n",
      "  \u001b[31m   \u001b[0m Exception: You tried to install \"pytorch\". The package named for PyTorch is \"torch\"\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mlegacy-install-failure\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while trying to install package.\n",
      "\u001b[31m╰─>\u001b[0m pytorch\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for output from the failure.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESG-BERT\n",
    "- Domain Specific BERT Model for Text Mining in Sustainable Investing\n",
    "- URL: https://huggingface.co/nbroad/ESG-BERT\n",
    "- This pre-trained model is able to classify each text and returns a label number which correlates to a textual label: \n",
    "    * __label__Business_Ethics :  0 \n",
    "    * __label__Data_Security :  1 \n",
    "    * __label__Access_And_Affordability :  2 \n",
    "    * __label__Business_Model_Resilience :  3 \n",
    "    * __label__Competitive_Behavior :  4 \n",
    "    * __label__Critical_Incident_Risk_Management :  5 \n",
    "    * __label__Customer_Welfare :  6 \n",
    "    * __label__Director_Removal :  7 \n",
    "    * __label__Employee_Engagement_Inclusion_And_Diversity :  8 \n",
    "    * __label__Employee_Health_And_Safety :  9 \n",
    "    * __label__Human_Rights_And_Community_Relations :  10 \n",
    "    * __label__Labor_Practices :  11 \n",
    "    * __label__Management_Of_Legal_And_Regulatory_Framework :  12 \n",
    "    * __label__Physical_Impacts_Of_Climate_Change :  13 \n",
    "    * __label__Product_Quality_And_Safety :  14 \n",
    "    * __label__Product_Design_And_Lifecycle_Management :  15 \n",
    "    * __label__Selling_Practices_And_Product_Labeling :  16 \n",
    "    * __label__Supply_Chain_Management :  17 \n",
    "    * __label__Systemic_Risk_Management :  18 \n",
    "    * __label__Waste_And_Hazardous_Materials_Management :  19 \n",
    "    * __label__Water_And_Wastewater_Management :  20 \n",
    "    * __label__Air_Quality :  21 \n",
    "    * __label__Customer_Privacy :  22 \n",
    "    * __label__Ecological_Impacts :  23 \n",
    "    * __label__Energy_Management :  24 \n",
    "    * __label__GHG_Emissions :  25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nbroad/ESG-BERT\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"nbroad/ESG-BERT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Mapping ESG-BERT's topics to S&P ESG Criteria Topics\n",
    "1. Map each criteria topic that is most relevant to the \"Health Care Equipments and Supplies\" industry to the 26 possible topics\n",
    "2. The remaining topics that cannot be mapped with the \"Health Care Equipments and Supplies\" Industry criteria topics, we will use the other criteria topics provided by S&P Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_to_criteria = {\n",
    "    \"Business_Ethics\": [\"Business Ethics\"],\n",
    "    \"Data_Security\": [\"Information Security/Cybersecurity & System Availability\"], # self added\n",
    "    \"Access_And_Affordability\": [\"Health Outcome Contribution\"], # self added\n",
    "    \"Business_Model_Resilience\": [\"Codes of Business Conduct\"], # self added\n",
    "    \"Competitive_Behavior\": [\"Business Ethics\"], # self added\n",
    "    \"Critical_Incident_Risk_Management\": [\"Risk & Crisis Management\"], # self added\n",
    "    \"Customer_Welfare\": [\"Customer Relationship Management\"], # self added\n",
    "    \"Director_Removal\": [\"Anti-Crime Policy & Measures\"], # self added\n",
    "    \"Employee_Engagement_Inclusion_And_Diversity\": [\"Human Capital Development\"],\n",
    "    \"Employee_Health_And_Safety\": [\"Operational Eco-Efficiency\"],\n",
    "    \"Human_Rights_And_Community_Relations\": [\"Community Relations\"], # self added\n",
    "    \"Labor_Practices\": [\"Labor Practice Indicators\"], # self added\n",
    "    \"Management_Of_Legal_And_Regulatory_Framework\": [\"Corporate Governance\"], # self added\n",
    "    \"Physical_Impacts_Of_Climate_Change\": [\"Climate Change\"],\n",
    "    \"Product_Quality_And_Safety\": [\"Product Quality & Recall Management\"],\n",
    "    \"Product_Design_And_Lifecycle_Management\": [\"Product Stewardship\"], # self added\n",
    "    \"Selling_Practices_And_Product_Labeling\": [\"Marketing Practices\"], # self added\n",
    "    \"Supply_Chain_Management\": [\"Supply Chain Management\"],\n",
    "    \"Systemic_Risk_Management\": [\"Risk & Crisis Management\"], # self added\n",
    "    \"Waste_And_Hazardous_Materials_Management\": [\"Operational Eco-Efficiency\"],\n",
    "    \"Water_And_Wastewater_Management\": [\"Operational Eco-Efficiency\"],\n",
    "    \"Air_Quality\": [\"Operational Eco-Efficiency\"],\n",
    "    \"Customer_Privacy\": [\"Privacy Protection\"], # self added\n",
    "    \"Ecological_Impacts\": [\"Natural Capital\"],\n",
    "    \"Energy_Management\": [\"Operational Eco-Efficiency\"],\n",
    "    \"GHG_Emissions\": [\"Climate Change\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Run report into ESG-BERT model to classify each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "def run_model(input_file, model):\n",
    "    counter = 1\n",
    "    max_seq_length = tokenizer.model_max_length\n",
    "    with open(input_file, \"r\") as f:\n",
    "        output = {}\n",
    "        for line in f:\n",
    "            if len(line) <= max_seq_length:\n",
    "                output['Line ' + str(counter)] = {}\n",
    "                inputs = tokenizer(line, return_tensors=\"pt\")\n",
    "                outputs = model(**inputs)\n",
    "                probs = outputs.logits.softmax(dim=1)\n",
    "\n",
    "                # Extract the top 3 probabilities and labels\n",
    "                top_probs, top_labels = torch.topk(probs, k=3)\n",
    "                # store output\n",
    "                output['Line ' + str(counter)]['Sentence'] = line\n",
    "                for i in range(3):\n",
    "                    label = model.config.id2label[top_labels[0][i].item()]\n",
    "                    prob = top_probs[0][i].item()\n",
    "                    output['Line ' + str(counter)][f'ESG BERT Topic {i+1}'] = (label, prob)\n",
    "                    \n",
    "                counter += 1\n",
    "            else:\n",
    "                # split input text into chunks\n",
    "                text_chunks = []\n",
    "                for i in range(math.ceil(len(line)/max_seq_length)):\n",
    "                    start = i * max_seq_length\n",
    "                    end = min((i+1)*max_seq_length, len(line))\n",
    "                    text_chunks.append(line[start:end])\n",
    "                for chunk in text_chunks:\n",
    "                    output['Line ' + str(counter)] = {}\n",
    "                    inputs = tokenizer(chunk, return_tensors=\"pt\", padding= True, truncation=True, max_length=max_seq_length)\n",
    "                    outputs = model(**inputs)\n",
    "                    probs = outputs.logits.softmax(dim=1)\n",
    "                    top_probs, top_labels = torch.topk(probs, k=3)\n",
    "                    \n",
    "                    output['Line ' + str(counter)]['Sentence'] = line\n",
    "                    for i in range(3):\n",
    "                        label = model.config.id2label[top_labels[0][i].item()]\n",
    "                        prob = top_probs[0][i].item()\n",
    "                        output['Line ' + str(counter)][f'ESG BERT Topic {i+1}'] = (label, prob)\n",
    "                    counter += 1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Mapping output labels to our criteria topics\n",
    "- We will map the output labels generated by ESG-BERT with the mapping, `mapped_to_criteria`\n",
    "- We also have decided to classify sentences whose label with the highest probability is less than 0.50 as `Non-ESG`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_output(result):\n",
    "    df = pd.DataFrame.from_dict(result, orient= 'index')\n",
    "    def mapperFunction(row):\n",
    "        value = row[1]\n",
    "        if value < 0.5:\n",
    "            return (\"NON-ESG\", value)\n",
    "        else:\n",
    "            return (mapped_to_criteria[row[0]], value)\n",
    "    df['Mapped Criteria Topic 1'] = df['ESG BERT Topic 1'].apply(lambda x: mapperFunction(x))\n",
    "    df['Mapped Criteria Topic 2'] = df['ESG BERT Topic 2'].apply(lambda x: mapperFunction(x))\n",
    "    df['Mapped Criteria Topic 3'] = df['ESG BERT Topic 3'].apply(lambda x: mapperFunction(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Export as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_output_to_csv(df, output_filename):\n",
    "    df.to_csv(output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Run all reports into the ESG-BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "folder_path = 'esg_reports'\n",
    "\n",
    "for foldername in os.listdir(folder_path):\n",
    "    company_folder_path = folder_path + '/' + foldername\n",
    "\n",
    "    if foldername == \".DS_Store\":\n",
    "        continue\n",
    "\n",
    "    for filename in os.listdir(company_folder_path):\n",
    "        if filename == \".DS_Store\":\n",
    "            continue\n",
    "        if not os.path.exists('data/' + company_folder_path):\n",
    "            os.makedirs('data/' + company_folder_path)\n",
    "\n",
    "        input_file = company_folder_path + '/' + filename\n",
    "        output_file = 'data/' + input_file.replace('.txt','.csv')\n",
    "        output_result = run_model(input_file, model)\n",
    "        output_df = process_output(output_result)\n",
    "        export_output_to_csv(output_df, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/esg_reports/ABT_Abbott/ABT_2021.txt\")\n",
    "df = df[['Unnamed: 0', 'Sentence']]\n",
    "df = df.rename(columns={\"Unnamed: 0\" : \"Line\"})\n",
    "df.to_csv(\"Result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Line 1</td>\n",
       "      <td>GLOBAL  SUSTAINABILITY  REPORT 2021For Abbott,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Line 2</td>\n",
       "      <td>In this report, we detail our progress  agains...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Line 3</td>\n",
       "      <td>The data presented  reflect 2021 performance u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Line 4</td>\n",
       "      <td>We have aligned our reporting  with the requir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Line 5</td>\n",
       "      <td>We have aligned our reporting  with the requir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>Line 2020</td>\n",
       "      <td>The goal of our three-year, $5 million  effort...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>Line 2021</td>\n",
       "      <td>The pilot  seeks to better understand and addr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>Line 2022</td>\n",
       "      <td>Focusing initial efforts in Columbus, Ohio, we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>Line 2023</td>\n",
       "      <td>In collaboration with the National Center for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>Line 2024</td>\n",
       "      <td>See page 18 of Abbott’s Access and Affordabili...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2024 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Line                                           Sentence\n",
       "0        Line 1  GLOBAL  SUSTAINABILITY  REPORT 2021For Abbott,...\n",
       "1        Line 2  In this report, we detail our progress  agains...\n",
       "2        Line 3  The data presented  reflect 2021 performance u...\n",
       "3        Line 4  We have aligned our reporting  with the requir...\n",
       "4        Line 5  We have aligned our reporting  with the requir...\n",
       "...         ...                                                ...\n",
       "2019  Line 2020  The goal of our three-year, $5 million  effort...\n",
       "2020  Line 2021  The pilot  seeks to better understand and addr...\n",
       "2021  Line 2022  Focusing initial efforts in Columbus, Ohio, we...\n",
       "2022  Line 2023  In collaboration with the National Center for ...\n",
       "2023  Line 2024  See page 18 of Abbott’s Access and Affordabili...\n",
       "\n",
       "[2024 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.width', 5)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
