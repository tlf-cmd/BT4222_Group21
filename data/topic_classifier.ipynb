{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.12.0-cp39-cp39-macosx_10_15_x86_64.whl (230.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.1/230.1 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting numpy<1.24,>=1.22\n",
      "  Downloading numpy-1.23.5-cp39-cp39-macosx_10_9_x86_64.whl (18.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting jax>=0.3.15\n",
      "  Downloading jax-0.4.7.tar.gz (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tensorboard<2.13,>=2.12\n",
      "  Downloading tensorboard-2.12.0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.32.0-cp39-cp39-macosx_10_14_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.12.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.22.1-cp37-abi3-macosx_10_9_universal2.whl (397 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m397.2/397.2 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting keras<2.13,>=2.12.0\n",
      "  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.0-py2.py3-none-macosx_10_9_x86_64.whl (26.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (21.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-23.3.3-py2.py3-none-any.whl (26 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.2.0-py3-none-any.whl (6.6 kB)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (58.0.4)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (4.5.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.2.1)\n",
      "Collecting tensorflow-estimator<2.13,>=2.12.0\n",
      "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Collecting ml_dtypes>=0.0.3\n",
      "  Downloading ml_dtypes-0.0.4-cp39-cp39-macosx_10_9_universal2.whl (226 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.2/226.2 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.7 in /opt/anaconda3/lib/python3.9/site-packages (from jax>=0.3.15->tensorflow) (1.7.1)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.53.0-cp39-cp39-macosx_10_10_universal2.whl (8.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.0.2)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.28.2)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.0-py3-none-macosx_10_9_x86_64.whl (4.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.3.4)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.6.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/anaconda3/lib/python3.9/site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.7.2)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.7)\n",
      "Collecting numpy<1.24,>=1.22\n",
      "  Downloading numpy-1.22.4-cp39-cp39-macosx_10_15_x86_64.whl (17.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.7/17.7 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/anaconda3/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: jax\n",
      "  Building wheel for jax (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jax: filename=jax-0.4.7-py3-none-any.whl size=1438288 sha256=f438daccdabfd0429e34959f3d19c6370d9bedfde3af7e58c07ebd2fbcb576f2\n",
      "  Stored in directory: /Users/yongler/Library/Caches/pip/wheels/e9/73/66/a8af684b751f8cf468ce4b76759785559cd0a35e5e2973fd2a\n",
      "Successfully built jax\n",
      "Installing collected packages: tensorboard-plugin-wit, libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, protobuf, oauthlib, numpy, keras, grpcio, google-pasta, gast, astunparse, absl-py, requests-oauthlib, opt-einsum, ml_dtypes, jax, google-auth-oauthlib, tensorboard, tensorflow\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.4\n",
      "    Uninstalling protobuf-3.19.4:\n",
      "      Successfully uninstalled protobuf-3.19.4\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.20.3\n",
      "    Uninstalling numpy-1.20.3:\n",
      "      Successfully uninstalled numpy-1.20.3\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.42.0\n",
      "    Uninstalling grpcio-1.42.0:\n",
      "      Successfully uninstalled grpcio-1.42.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.3.0 requires daal==2021.2.3, which is not installed.\n",
      "web3 5.28.0 requires protobuf<4,>=3.10.0, but you have protobuf 4.22.1 which is incompatible.\n",
      "numba 0.54.1 requires numpy<1.21,>=1.17, but you have numpy 1.22.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed absl-py-1.4.0 astunparse-1.6.3 flatbuffers-23.3.3 gast-0.4.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.53.0 jax-0.4.7 keras-2.12.0 libclang-16.0.0 ml_dtypes-0.0.4 numpy-1.22.4 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.22.1 requests-oauthlib-1.3.1 tensorboard-2.12.0 tensorboard-data-server-0.7.0 tensorboard-plugin-wit-1.8.1 tensorflow-2.12.0 tensorflow-estimator-2.12.0 tensorflow-io-gcs-filesystem-0.32.0 termcolor-2.2.0\n",
      "Collecting pytorch\n",
      "  Downloading pytorch-1.0.2.tar.gz (689 bytes)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: pytorch\n",
      "  Building wheel for pytorch (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[6 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/27/xh3tm0h964n5gjzv1brx5vrc0000gn/T/pip-install-iiwqbamx/pytorch_f64211def52c4f0a80a616ac12f963e6/setup.py\", line 15, in <module>\n",
      "  \u001b[31m   \u001b[0m     raise Exception(message)\n",
      "  \u001b[31m   \u001b[0m Exception: You tried to install \"pytorch\". The package named for PyTorch is \"torch\"\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for pytorch\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for pytorch\n",
      "Failed to build pytorch\n",
      "Installing collected packages: pytorch\n",
      "  Running setup.py install for pytorch ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mRunning setup.py install for pytorch\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[6 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/27/xh3tm0h964n5gjzv1brx5vrc0000gn/T/pip-install-iiwqbamx/pytorch_f64211def52c4f0a80a616ac12f963e6/setup.py\", line 11, in <module>\n",
      "  \u001b[31m   \u001b[0m     raise Exception(message)\n",
      "  \u001b[31m   \u001b[0m Exception: You tried to install \"pytorch\". The package named for PyTorch is \"torch\"\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mlegacy-install-failure\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while trying to install package.\n",
      "\u001b[31m╰─>\u001b[0m pytorch\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for output from the failure.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install pytorch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESG-BERT\n",
    "- Domain Specific BERT Model for Text Mining in Sustainable Investing\n",
    "- URL: https://huggingface.co/nbroad/ESG-BERT\n",
    "- This pre-trained model is able to classify each text and returns a label number which correlates to a textual label: \n",
    "    * __label__Business_Ethics :  0 \n",
    "    * __label__Data_Security :  1 \n",
    "    * __label__Access_And_Affordability :  2 \n",
    "    * __label__Business_Model_Resilience :  3 \n",
    "    * __label__Competitive_Behavior :  4 \n",
    "    * __label__Critical_Incident_Risk_Management :  5 \n",
    "    * __label__Customer_Welfare :  6 \n",
    "    * __label__Director_Removal :  7 \n",
    "    * __label__Employee_Engagement_Inclusion_And_Diversity :  8 \n",
    "    * __label__Employee_Health_And_Safety :  9 \n",
    "    * __label__Human_Rights_And_Community_Relations :  10 \n",
    "    * __label__Labor_Practices :  11 \n",
    "    * __label__Management_Of_Legal_And_Regulatory_Framework :  12 \n",
    "    * __label__Physical_Impacts_Of_Climate_Change :  13 \n",
    "    * __label__Product_Quality_And_Safety :  14 \n",
    "    * __label__Product_Design_And_Lifecycle_Management :  15 \n",
    "    * __label__Selling_Practices_And_Product_Labeling :  16 \n",
    "    * __label__Supply_Chain_Management :  17 \n",
    "    * __label__Systemic_Risk_Management :  18 \n",
    "    * __label__Waste_And_Hazardous_Materials_Management :  19 \n",
    "    * __label__Water_And_Wastewater_Management :  20 \n",
    "    * __label__Air_Quality :  21 \n",
    "    * __label__Customer_Privacy :  22 \n",
    "    * __label__Ecological_Impacts :  23 \n",
    "    * __label__Energy_Management :  24 \n",
    "    * __label__GHG_Emissions :  25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nbroad/ESG-BERT\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"nbroad/ESG-BERT\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Mapping ESG-BERT's topics to S&P ESG Criteria Topics\n",
    "1. Map each criteria topic that is most relevant to the \"Health Care Equipments and Supplies\" industry to the 26 possible topics\n",
    "2. The remaining topics that cannot be mapped with the \"Health Care Equipments and Supplies\" Industry criteria topics, we will use the other criteria topics provided by S&P Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_to_criteria = {\n",
    "    \"Business_Ethics\": [\"Business Ethics\"],\n",
    "    \"Data_Security\": [\"Information Security/Cybersecurity & System Availability\"], # self added\n",
    "    \"Access_And_Affordability\": [\"Health Outcome Contribution\"], # self added\n",
    "    \"Business_Model_Resilience\": [\"Codes of Business Conduct\"], # self added\n",
    "    \"Competitive_Behavior\": [\"Business Ethics\"], # self added\n",
    "    \"Critical_Incident_Risk_Management\": [\"Risk & Crisis Management\"], # self added\n",
    "    \"Customer_Welfare\": [\"Customer Relationship Management\"], # self added\n",
    "    \"Director_Removal\": [\"Anti-Crime Policy & Measures\"], # self added\n",
    "    \"Employee_Engagement_Inclusion_And_Diversity\": [\"Human Capital Development\"],\n",
    "    \"Employee_Health_And_Safety\": [\"Operational Eco-Efficiency\"],\n",
    "    \"Human_Rights_And_Community_Relations\": [\"Community Relations\"],\n",
    "    \"Labor_Practices\": [\"Labor Practice Indicators\"], # self added\n",
    "    \"Management_Of_Legal_And_Regulatory_Framework\": [\"Corporate Governance\"], # self added\n",
    "    \"Physical_Impacts_Of_Climate_Change\": [\"Climate Change\"],\n",
    "    \"Product_Quality_And_Safety\": [\"Product Quality & Recall Management\"],\n",
    "    \"Product_Design_And_Lifecycle_Management\": [\"Product Stewardship\"], # self added\n",
    "    \"Selling_Practices_And_Product_Labeling\": [\"Marketing Practices\"], # self added\n",
    "    \"Supply_Chain_Management\": [\"Supply Chain Management\"],\n",
    "    \"Systemic_Risk_Management\": [\"Risk & Crisis Management\"], # self added\n",
    "    \"Waste_And_Hazardous_Materials_Management\": [\"Operational Eco-Efficiency\"],\n",
    "    \"Water_And_Wastewater_Management\": [\"Operational Eco-Efficiency\"],\n",
    "    \"Air_Quality\": [\"Operational Eco-Efficiency\"],\n",
    "    \"Customer_Privacy\": [\"Privacy Protection\"], # self added\n",
    "    \"Ecological_Impacts\": [\"Natural Capital\"],\n",
    "    \"Energy_Management\": [\"Operational Eco-Efficiency\"],\n",
    "    \"GHG_Emissions\": [\"Climate Change\"]\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Run each report into ESG-BERT Pre-trained model to classify each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "def run_model(input_file, model):\n",
    "    counter = 1\n",
    "    max_seq_length = tokenizer.model_max_length\n",
    "    with open(input_file, \"r\") as f:\n",
    "        output = {}\n",
    "        for line in f:\n",
    "            if len(line) <= max_seq_length:\n",
    "                output['Line ' + str(counter)] = {}\n",
    "                inputs = tokenizer(line, return_tensors=\"pt\")\n",
    "                outputs = model(**inputs)\n",
    "                probs = outputs.logits.softmax(dim=1)\n",
    "\n",
    "                # Extract the top 3 probabilities and labels\n",
    "                top_probs, top_labels = torch.topk(probs, k=3)\n",
    "                # store output\n",
    "                output['Line ' + str(counter)]['Sentence'] = line\n",
    "                for i in range(3):\n",
    "                    label = model.config.id2label[top_labels[0][i].item()]\n",
    "                    prob = top_probs[0][i].item()\n",
    "                    output['Line ' + str(counter)][f'ESG BERT Topic {i+1}'] = (label, prob)\n",
    "                    \n",
    "                counter += 1\n",
    "            else:\n",
    "                # split input text into chunks\n",
    "                text_chunks = []\n",
    "                for i in range(math.ceil(len(line)/max_seq_length)):\n",
    "                    start = i * max_seq_length\n",
    "                    end = min((i+1)*max_seq_length, len(line))\n",
    "                    text_chunks.append(line[start:end])\n",
    "                for chunk in text_chunks:\n",
    "                    output['Line ' + str(counter)] = {}\n",
    "                    inputs = tokenizer(chunk, return_tensors=\"pt\", padding= True, truncation=True, max_length=max_seq_length)\n",
    "                    outputs = model(**inputs)\n",
    "                    probs = outputs.logits.softmax(dim=1)\n",
    "                    top_probs, top_labels = torch.topk(probs, k=3)\n",
    "                    \n",
    "                    output['Line ' + str(counter)]['Sentence'] = line\n",
    "                    for i in range(3):\n",
    "                        label = model.config.id2label[top_labels[0][i].item()]\n",
    "                        prob = top_probs[0][i].item()\n",
    "                        output['Line ' + str(counter)][f'ESG BERT Topic {i+1}'] = (label, prob)\n",
    "                    counter += 1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_output(result):\n",
    "    df = pd.DataFrame.from_dict(result, orient= 'index')\n",
    "    def mapperFunction(row):\n",
    "        value = row[1]\n",
    "        if value < 0.5:\n",
    "            return (\"NON-ESG\", value)\n",
    "        else:\n",
    "            return (mapped_to_criteria[row[0]], value)\n",
    "    df['Mapped Criteria Topic 1'] = df['ESG BERT Topic 1'].apply(lambda x: mapperFunction(x))\n",
    "    df['Mapped Criteria Topic 2'] = df['ESG BERT Topic 2'].apply(lambda x: mapperFunction(x))\n",
    "    df['Mapped Criteria Topic 3'] = df['ESG BERT Topic 3'].apply(lambda x: mapperFunction(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_output_to_csv(df, output_filename):\n",
    "    df.to_csv(output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "folder_path = 'esg_reports'\n",
    "\n",
    "for foldername in os.listdir(folder_path):\n",
    "    company_folder_path = folder_path + '/' + foldername\n",
    "\n",
    "    if foldername == \".DS_Store\":\n",
    "        continue\n",
    "\n",
    "    for filename in os.listdir(company_folder_path):\n",
    "        if filename == \".DS_Store\":\n",
    "            continue\n",
    "        if not os.path.exists('data/' + company_folder_path):\n",
    "            os.makedirs('data/' + company_folder_path)\n",
    "\n",
    "        input_file = company_folder_path + '/' + filename\n",
    "        output_file = 'data/' + input_file.replace('.txt','.csv')\n",
    "        output_result = run_model(input_file, model)\n",
    "        output_df = process_output(output_result)\n",
    "        export_output_to_csv(output_df, output_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Mapping output labels to our criteria topics\n",
    "- We will map the output labels generated by ESG-BERT with the mapping, `mapped_to_criteria`\n",
    "- We also have decided to classify sentences whose label with the highest probability is less than 0.50 as `Non-ESG`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>ESG BERT Topic 1</th>\n",
       "      <th>ESG BERT Topic 2</th>\n",
       "      <th>ESG BERT Topic 3</th>\n",
       "      <th>Mapped Criteria Topic 1</th>\n",
       "      <th>Mapped Criteria Topic 2</th>\n",
       "      <th>Mapped Criteria Topic 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Line 6</td>\n",
       "      <td>Section 1: Promoting Ethics and Integrity .\\n</td>\n",
       "      <td>('Business_Ethics', 0.957015872001648)</td>\n",
       "      <td>('Competitive_Behavior', 0.004411257803440094)</td>\n",
       "      <td>('Data_Security', 0.002768311183899641)</td>\n",
       "      <td>(['Business Ethics'], 0.957015872001648)</td>\n",
       "      <td>('NON-ESG', 0.004411257803440094)</td>\n",
       "      <td>('NON-ESG', 0.002768311183899641)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Line 7</td>\n",
       "      <td>Our Compliance Program .\\n</td>\n",
       "      <td>('Business_Ethics', 0.6227568984031677)</td>\n",
       "      <td>('Management_Of_Legal_And_Regulatory_Framework...</td>\n",
       "      <td>('Human_Rights_And_Community_Relations', 0.020...</td>\n",
       "      <td>(['Business Ethics'], 0.6227568984031677)</td>\n",
       "      <td>('NON-ESG', 0.19719147682189941)</td>\n",
       "      <td>('NON-ESG', 0.020562920719385147)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Line 8</td>\n",
       "      <td>Combating Corruption and Bribery .\\n</td>\n",
       "      <td>('Business_Ethics', 0.9651241302490234)</td>\n",
       "      <td>('Competitive_Behavior', 0.003234578762203455)</td>\n",
       "      <td>('Data_Security', 0.0028390565421432257)</td>\n",
       "      <td>(['Business Ethics'], 0.9651241302490234)</td>\n",
       "      <td>('NON-ESG', 0.003234578762203455)</td>\n",
       "      <td>('NON-ESG', 0.0028390565421432257)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Line 9</td>\n",
       "      <td>Public Policy Engagement .\\n</td>\n",
       "      <td>('Management_Of_Legal_And_Regulatory_Framework...</td>\n",
       "      <td>('Human_Rights_And_Community_Relations', 0.299...</td>\n",
       "      <td>('Business_Model_Resilience', 0.04645168036222...</td>\n",
       "      <td>('NON-ESG', 0.3524152934551239)</td>\n",
       "      <td>('NON-ESG', 0.2992231249809265)</td>\n",
       "      <td>('NON-ESG', 0.04645168036222458)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Line 10</td>\n",
       "      <td>Section 2: Ensuring Quality and Safety .\\n</td>\n",
       "      <td>('Employee_Health_And_Safety', 0.716966450214386)</td>\n",
       "      <td>('Product_Quality_And_Safety', 0.1416839808225...</td>\n",
       "      <td>('Product_Design_And_Lifecycle_Management', 0....</td>\n",
       "      <td>(['Operational Eco-Efficiency'], 0.71696645021...</td>\n",
       "      <td>('NON-ESG', 0.14168398082256317)</td>\n",
       "      <td>('NON-ESG', 0.016787203028798103)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0                                       Sentence  \\\n",
       "5     Line 6  Section 1: Promoting Ethics and Integrity .\\n   \n",
       "6     Line 7                     Our Compliance Program .\\n   \n",
       "7     Line 8           Combating Corruption and Bribery .\\n   \n",
       "8     Line 9                   Public Policy Engagement .\\n   \n",
       "9    Line 10     Section 2: Ensuring Quality and Safety .\\n   \n",
       "\n",
       "                                    ESG BERT Topic 1  \\\n",
       "5             ('Business_Ethics', 0.957015872001648)   \n",
       "6            ('Business_Ethics', 0.6227568984031677)   \n",
       "7            ('Business_Ethics', 0.9651241302490234)   \n",
       "8  ('Management_Of_Legal_And_Regulatory_Framework...   \n",
       "9  ('Employee_Health_And_Safety', 0.716966450214386)   \n",
       "\n",
       "                                    ESG BERT Topic 2  \\\n",
       "5     ('Competitive_Behavior', 0.004411257803440094)   \n",
       "6  ('Management_Of_Legal_And_Regulatory_Framework...   \n",
       "7     ('Competitive_Behavior', 0.003234578762203455)   \n",
       "8  ('Human_Rights_And_Community_Relations', 0.299...   \n",
       "9  ('Product_Quality_And_Safety', 0.1416839808225...   \n",
       "\n",
       "                                    ESG BERT Topic 3  \\\n",
       "5            ('Data_Security', 0.002768311183899641)   \n",
       "6  ('Human_Rights_And_Community_Relations', 0.020...   \n",
       "7           ('Data_Security', 0.0028390565421432257)   \n",
       "8  ('Business_Model_Resilience', 0.04645168036222...   \n",
       "9  ('Product_Design_And_Lifecycle_Management', 0....   \n",
       "\n",
       "                             Mapped Criteria Topic 1  \\\n",
       "5           (['Business Ethics'], 0.957015872001648)   \n",
       "6          (['Business Ethics'], 0.6227568984031677)   \n",
       "7          (['Business Ethics'], 0.9651241302490234)   \n",
       "8                    ('NON-ESG', 0.3524152934551239)   \n",
       "9  (['Operational Eco-Efficiency'], 0.71696645021...   \n",
       "\n",
       "             Mapped Criteria Topic 2             Mapped Criteria Topic 3  \n",
       "5  ('NON-ESG', 0.004411257803440094)   ('NON-ESG', 0.002768311183899641)  \n",
       "6   ('NON-ESG', 0.19719147682189941)   ('NON-ESG', 0.020562920719385147)  \n",
       "7  ('NON-ESG', 0.003234578762203455)  ('NON-ESG', 0.0028390565421432257)  \n",
       "8    ('NON-ESG', 0.2992231249809265)    ('NON-ESG', 0.04645168036222458)  \n",
       "9   ('NON-ESG', 0.14168398082256317)   ('NON-ESG', 0.016787203028798103)  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.read_csv(\"data/esg_reports/ABT_Abbott/ABT_2018.txt\")\n",
    "a[5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
