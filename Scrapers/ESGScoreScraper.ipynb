{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Run Selenium and BeautifulSoup to scrape S&P Global ESG Scores page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/27/xh3tm0h964n5gjzv1brx5vrc0000gn/T/ipykernel_42220/3146512397.py:10: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(\"/chromedriver\", options=chrome_options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Iteration 1: SCRAPING Apple Inc.... #####\n",
      "##### SCRAPING DONE FOR Apple Inc. #####\n",
      "##### Iteration 2: SCRAPING AbbVie Inc.... #####\n",
      "##### SCRAPING DONE FOR AbbVie Inc. #####\n",
      "##### Iteration 3: SCRAPING Amazon.com, Inc.... #####\n",
      "##### SCRAPING DONE FOR Amazon.com, Inc. #####\n",
      "##### Iteration 4: SCRAPING Chevron Corporation... #####\n",
      "##### SCRAPING DONE FOR Chevron Corporation #####\n",
      "##### Iteration 5: SCRAPING Alphabet Inc.... #####\n",
      "##### SCRAPING DONE FOR Alphabet Inc. #####\n",
      "##### Iteration 6: SCRAPING The Home Depot, Inc.... #####\n",
      "##### SCRAPING DONE FOR The Home Depot, Inc. #####\n",
      "##### Iteration 7: SCRAPING Johnson & Johnson... #####\n",
      "unable to scrape JNJ\n",
      "##### SCRAPING DONE FOR Johnson & Johnson #####\n",
      "##### Iteration 8: SCRAPING JPMorgan Chase & Co.... #####\n",
      "##### SCRAPING DONE FOR JPMorgan Chase & Co. #####\n",
      "##### Iteration 9: SCRAPING Eli Lilly and Company... #####\n",
      "##### SCRAPING DONE FOR Eli Lilly and Company #####\n",
      "##### Iteration 10: SCRAPING Mastercard Incorporated... #####\n",
      "##### SCRAPING DONE FOR Mastercard Incorporated #####\n",
      "##### Iteration 11: SCRAPING Meta Platforms, Inc.... #####\n",
      "##### SCRAPING DONE FOR Meta Platforms, Inc. #####\n",
      "##### Iteration 12: SCRAPING Merck & Co., Inc.... #####\n",
      "##### SCRAPING DONE FOR Merck & Co., Inc. #####\n",
      "##### Iteration 13: SCRAPING Microsoft Corporation... #####\n",
      "##### SCRAPING DONE FOR Microsoft Corporation #####\n",
      "##### Iteration 14: SCRAPING NVIDIA Corporation... #####\n",
      "##### SCRAPING DONE FOR NVIDIA Corporation #####\n",
      "##### Iteration 15: SCRAPING Pfizer Inc.... #####\n",
      "##### SCRAPING DONE FOR Pfizer Inc. #####\n",
      "##### Iteration 16: SCRAPING The Procter & Gamble Company... #####\n",
      "##### SCRAPING DONE FOR The Procter & Gamble Company #####\n",
      "##### Iteration 17: SCRAPING Tesla, Inc.... #####\n",
      "##### SCRAPING DONE FOR Tesla, Inc. #####\n",
      "##### Iteration 18: SCRAPING UnitedHealth Group Incorporated... #####\n",
      "##### SCRAPING DONE FOR UnitedHealth Group Incorporated #####\n",
      "##### Iteration 19: SCRAPING Visa Inc.... #####\n",
      "##### SCRAPING DONE FOR Visa Inc. #####\n",
      "##### Iteration 20: SCRAPING Exxon Mobil Corporation... #####\n",
      "##### SCRAPING DONE FOR Exxon Mobil Corporation #####\n",
      "#########################\n",
      "##### SCRAPING COMPLETED #####\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(\"/chromedriver\", options=chrome_options)\n",
    "\n",
    "driver.get(\"https://www.spglobal.com/esg/scores/\")\n",
    "time.sleep(3)\n",
    "click_accept = driver.find_elements(By.XPATH, '//*[@id=\"onetrust-accept-btn-handler\"]')\n",
    "click_accept[0].click()\n",
    "\n",
    "historical_scores = {}\n",
    "company_data = {}\n",
    "\n",
    "# Key: Ticker, Value: Official Company Name (Based on S&P Global website)\n",
    "companies = {\n",
    "    \"AAPL\": \"Apple Inc.\",\n",
    "    \"ABBV\": \"AbbVie Inc.\",\n",
    "    \"AMZN\": \"Amazon.com, Inc.\",\n",
    "    \"CVX\": \"Chevron Corporation\",\n",
    "    \"GOOGL\": \"Alphabet Inc.\",\n",
    "    \"HD\": \"The Home Depot, Inc.\",\n",
    "    \"JNJ\": \"Johnson & Johnson\",\n",
    "    \"JPM\": \"JPMorgan Chase & Co.\",\n",
    "    \"LLY\": \"Eli Lilly and Company\",\n",
    "    \"MA\": \"Mastercard Incorporated\",\n",
    "    \"META\": \"Meta Platforms, Inc.\",\n",
    "    \"MRK\": \"Merck & Co., Inc.\",\n",
    "    \"MSFT\": \"Microsoft Corporation\",\n",
    "    \"NVDA\": \"NVIDIA Corporation\",\n",
    "    \"PFE\": \"Pfizer Inc.\",\n",
    "    \"PG\": \"The Procter & Gamble Company\",\n",
    "    \"TSLA\": \"Tesla, Inc.\",\n",
    "    \"UNH\": \"UnitedHealth Group Incorporated\",\n",
    "    \"V\": \"Visa Inc.\",\n",
    "    \"XOM\": \"Exxon Mobil Corporation\"\n",
    "}\n",
    "\n",
    "\n",
    "i = 1\n",
    "for ticker, name in companies.items():\n",
    "    print(f\"##### Iteration {i}: SCRAPING {name} #####\")\n",
    "    if i == 1:\n",
    "        search_box = driver.find_elements(By.XPATH, \"/html/body/div[3]/div[11]/div/div[3]/div/div/div[2]/div[1]/input\")\n",
    "        search_box[0].send_keys(name)\n",
    "    else:\n",
    "        search_box = driver.find_elements(By.XPATH, \"/html/body/div[3]/div[1]/div[3]/div/div/div[2]/div[1]/input\")\n",
    "        search_box[0].send_keys(name)\n",
    "    time.sleep(1)\n",
    "    search_box[0].send_keys(Keys.ENTER)\n",
    "    time.sleep(5)\n",
    "\n",
    "    try:\n",
    "        ESG_score = driver.find_elements(By.XPATH, '//*[@id=\"esg-score\"]')[0].text\n",
    "        industry = driver.find_elements(By.XPATH, '//*[@id=\"company-industry\"]')[0].text\n",
    "        company_data[ticker] = industry\n",
    "        time.sleep(3)\n",
    "\n",
    "        historical_scores[ticker] = {}\n",
    "        historical_scores[ticker]['ESG Scores By Year'] = []\n",
    "        historical_scores[ticker]['ESG Scores By Category'] = {}\n",
    "        historical_scores[ticker]['Company Performance'] = []\n",
    "        historical_scores[ticker]['Industry Best Performance'] = []\n",
    "        historical_scores[ticker]['Industry Mean Performance'] = []\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        historical_chart = soup.find('g', {'class': 'highcharts-markers highcharts-series-0 highcharts-line-series highcharts-tracker'})\n",
    "        points = historical_chart.find_all('path', {'class':'highcharts-point'})\n",
    "        for point in points:\n",
    "            label = point.get('aria-label')\n",
    "            historical_scores[ticker]['ESG Scores By Year'].append(label)\n",
    "\n",
    "        company_perf = soup.find('g', {'class' : 'highcharts-markers highcharts-series-0 highcharts-area-series highcharts-tracker'})\n",
    "        company_points = company_perf.find_all('path', {'class': 'highcharts-point'})\n",
    "        for point in company_points:\n",
    "            label = point.get('aria-label')\n",
    "            historical_scores[ticker]['Company Performance'].append(label)\n",
    "\n",
    "        industry_mean = soup.find('g', {'class' : 'highcharts-markers highcharts-series-2 highcharts-line-series highcharts-tracker'})\n",
    "        industry_mean_points = industry_mean.find_all('path', {'class': 'highcharts-point'})\n",
    "        for point in industry_mean_points:\n",
    "            label = point.get('aria-label')\n",
    "            historical_scores[ticker]['Industry Mean Performance'].append(label)\n",
    "\n",
    "        industry_best = soup.find('g', {'class' : 'highcharts-markers highcharts-series-1 highcharts-line-series highcharts-tracker'})\n",
    "        industry_best_points = industry_best.find_all('path', {'class': 'highcharts-point'})\n",
    "        for point in industry_best_points:\n",
    "            label = point.get('aria-label')\n",
    "            historical_scores[ticker]['Industry Best Performance'].append(label)\n",
    "\n",
    "        environmental_score_div = soup.find('div', {'class': 'dimention-chart1'})\n",
    "        environmental_scores = environmental_score_div.find_all('li')\n",
    "        historical_scores[ticker]['ESG Scores By Category']['Environmental'] = []\n",
    "        for score in environmental_scores:\n",
    "            historical_scores[ticker]['ESG Scores By Category']['Environmental'].append(score.text)\n",
    "\n",
    "        social_score_div = soup.find('div', {'class': 'dimention-chart2'})\n",
    "        social_scores = social_score_div.find_all('li')\n",
    "        historical_scores[ticker]['ESG Scores By Category']['Social'] = []\n",
    "        for score in social_scores:\n",
    "            historical_scores[ticker]['ESG Scores By Category']['Social'].append(score.text)\n",
    "\n",
    "        governance_score_div = soup.find('div', {'class': 'dimention-chart3'})\n",
    "        governance_scores = governance_score_div.find_all('li')\n",
    "        historical_scores[ticker]['ESG Scores By Category']['Governance'] = []\n",
    "        for score in governance_scores:\n",
    "            historical_scores[ticker]['ESG Scores By Category']['Governance'].append(score.text)\n",
    "\n",
    "    except:\n",
    "        if i == 1:\n",
    "            search_box = driver.find_elements(By.XPATH, \"/html/body/div[3]/div[11]/div/div[3]/div/div/div[2]/div[1]/input\")\n",
    "            search_box[0].clear()\n",
    "        else:\n",
    "            search_box = driver.find_elements(By.XPATH, \"/html/body/div[3]/div[1]/div[3]/div/div/div[2]/div[1]/input\")\n",
    "            search_box[0].clear()\n",
    "        print(f\"unable to scrape {ticker}\")\n",
    "    i += 1\n",
    "    print(f\"##### SCRAPING DONE FOR {name} #####\")\n",
    "\n",
    "driver.close()\n",
    "print(\"#########################\")\n",
    "print(f\"##### SCRAPING COMPLETED #####\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function to Process Scrapped Data\n",
    "def process_historical_scores(scores):\n",
    "    \"\"\"\n",
    "    Takes in scrapped data and extract Historical ESG Scores, Company Performance in various categories,\n",
    "    and Industry Performances (Mean and Best) in the same categories.\n",
    "\n",
    "    Returns historical_ESG_scores -> dict, ESG_component_scores -> dict, company_performances -> dict\n",
    "    \"\"\"\n",
    "    historical_ESG_scores = {}\n",
    "    ESG_component_scores = {}\n",
    "    company_performances = {}\n",
    "\n",
    "    for ticker, scrapped_data in scores.items():\n",
    "        historical_ESG_scores[ticker] = {}\n",
    "        company_performances[ticker] = {}\n",
    "        ESG_component_scores[ticker] = {}\n",
    "\n",
    "        for data in scrapped_data['ESG Scores By Year']:\n",
    "            split = data.split(\", \")\n",
    "            year = split[0].split(\". \")[-1]\n",
    "            esg_score = split[-1].split(\".\")[0]\n",
    "            historical_ESG_scores[ticker][int(year)] = int(esg_score)\n",
    "        \n",
    "        for component, data in scrapped_data['ESG Scores By Category'].items():\n",
    "            ESG_component_scores[ticker][component] = {}\n",
    "            ESG_component_scores[ticker][component]['Company'] = int(data[0].split(\" \")[-1])\n",
    "            ESG_component_scores[ticker][component]['Industry Mean'] = int(data[1].split(\" \")[-1])\n",
    "            ESG_component_scores[ticker][component]['Industry Best'] = int(data[2].split(\" \")[-1])\n",
    "\n",
    "        for data in scrapped_data['Company Performance']:\n",
    "            if \"/ \" in data: # to handle \"Information Security/ Cybersecurity & System Availability\"\n",
    "                data = data.replace(\"/ \", \" \")\n",
    "            split = data.split(\", \")\n",
    "            category = split[0].split(\". \")[-1]\n",
    "            perf_score = split[-1].split(\".\")[0]\n",
    "            if category not in company_performances[ticker].keys():\n",
    "                company_performances[ticker][category] = {}    \n",
    "            company_performances[ticker][category]['Company'] = int(perf_score)\n",
    "\n",
    "        for data in scrapped_data['Industry Best Performance']:\n",
    "            if \"/ \" in data: # to handle \"Information Security/ Cybersecurity & System Availability\"\n",
    "                data = data.replace(\"/ \", \" \")\n",
    "            split = data.split(\", \")\n",
    "            category = split[0].split(\". \")[-1]\n",
    "            perf_score = split[-1].split(\".\")[0]\n",
    "            if category not in company_performances[ticker].keys():\n",
    "                company_performances[ticker][category] = {}  \n",
    "            company_performances[ticker][category]['Industry Best'] = int(perf_score)\n",
    "\n",
    "        for data in scrapped_data['Industry Mean Performance']:\n",
    "            if \"/ \" in data: # to handle \"Information Security/ Cybersecurity & System Availability\"\n",
    "                data = data.replace(\"/ \", \" \")\n",
    "            split = data.split(\", \")\n",
    "            category = split[0].split(\". \")[-1]\n",
    "            perf_score = split[-1].split(\".\")[0]\n",
    "            if category not in company_performances[ticker].keys():\n",
    "                company_performances[ticker][category] = {}  \n",
    "            company_performances[ticker][category]['Industry Mean'] = int(perf_score)\n",
    "\n",
    "    return historical_ESG_scores, ESG_component_scores, company_performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_ESG_scores, ESG_component_scores, company_performances = process_historical_scores(historical_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Industry Mean</th>\n",
       "      <th>Industry Best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Environmental</th>\n",
       "      <td>61</td>\n",
       "      <td>33</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Social</th>\n",
       "      <td>24</td>\n",
       "      <td>29</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Governance</th>\n",
       "      <td>29</td>\n",
       "      <td>32</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Company  Industry Mean  Industry Best\n",
       "Environmental       61             33             95\n",
       "Social              24             29             89\n",
       "Governance          29             32             89"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "component_dict = {}\n",
    "for ticker, data in ESG_component_scores.items():\n",
    "    component_dict[ticker] = pd.DataFrame.from_dict(data, orient='index')\n",
    "\n",
    "component_dict['AAPL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Industry Best</th>\n",
       "      <th>Industry Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Climate Strategy</th>\n",
       "      <td>78</td>\n",
       "      <td>98</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Human Capital Development</th>\n",
       "      <td>45</td>\n",
       "      <td>100</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Human Rights</th>\n",
       "      <td>33</td>\n",
       "      <td>100</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Information Security Cybersecurity &amp; System Availability</th>\n",
       "      <td>16</td>\n",
       "      <td>93</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Innovation Management</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Operational Eco-Efficiency</th>\n",
       "      <td>74</td>\n",
       "      <td>100</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product Stewardship</th>\n",
       "      <td>59</td>\n",
       "      <td>100</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Supply Chain Management</th>\n",
       "      <td>6</td>\n",
       "      <td>99</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Company  Industry Best  \\\n",
       "Climate Strategy                                         78             98   \n",
       "Human Capital Development                                45            100   \n",
       "Human Rights                                             33            100   \n",
       "Information Security Cybersecurity & System Ava...       16             93   \n",
       "Innovation Management                                     4            100   \n",
       "Operational Eco-Efficiency                               74            100   \n",
       "Product Stewardship                                      59            100   \n",
       "Supply Chain Management                                   6             99   \n",
       "\n",
       "                                                    Industry Mean  \n",
       "Climate Strategy                                               33  \n",
       "Human Capital Development                                      42  \n",
       "Human Rights                                                   27  \n",
       "Information Security Cybersecurity & System Ava...             26  \n",
       "Innovation Management                                          19  \n",
       "Operational Eco-Efficiency                                     36  \n",
       "Product Stewardship                                            25  \n",
       "Supply Chain Management                                        27  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_dict = {}\n",
    "for ticker, data in company_performances.items():\n",
    "    performance_dict[ticker] = pd.DataFrame.from_dict(data, orient='index').sort_index()\n",
    "performance_dict['AAPL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>CVX</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>HD</th>\n",
       "      <th>JPM</th>\n",
       "      <th>LLY</th>\n",
       "      <th>MA</th>\n",
       "      <th>META</th>\n",
       "      <th>MRK</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>NVDA</th>\n",
       "      <th>PFE</th>\n",
       "      <th>PG</th>\n",
       "      <th>TSLA</th>\n",
       "      <th>UNH</th>\n",
       "      <th>V</th>\n",
       "      <th>XOM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>27</td>\n",
       "      <td>80</td>\n",
       "      <td>14</td>\n",
       "      <td>43</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>45</td>\n",
       "      <td>30</td>\n",
       "      <td>45</td>\n",
       "      <td>11</td>\n",
       "      <td>39</td>\n",
       "      <td>58</td>\n",
       "      <td>69</td>\n",
       "      <td>27</td>\n",
       "      <td>52</td>\n",
       "      <td>13</td>\n",
       "      <td>76</td>\n",
       "      <td>53</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>29</td>\n",
       "      <td>76</td>\n",
       "      <td>18</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>31</td>\n",
       "      <td>37</td>\n",
       "      <td>30</td>\n",
       "      <td>58</td>\n",
       "      <td>15</td>\n",
       "      <td>40</td>\n",
       "      <td>57</td>\n",
       "      <td>72</td>\n",
       "      <td>29</td>\n",
       "      <td>60</td>\n",
       "      <td>14</td>\n",
       "      <td>69</td>\n",
       "      <td>58</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>29</td>\n",
       "      <td>81</td>\n",
       "      <td>21</td>\n",
       "      <td>42</td>\n",
       "      <td>40</td>\n",
       "      <td>26</td>\n",
       "      <td>37</td>\n",
       "      <td>29</td>\n",
       "      <td>62</td>\n",
       "      <td>14</td>\n",
       "      <td>39</td>\n",
       "      <td>58</td>\n",
       "      <td>74</td>\n",
       "      <td>31</td>\n",
       "      <td>60</td>\n",
       "      <td>15</td>\n",
       "      <td>70</td>\n",
       "      <td>63</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>32</td>\n",
       "      <td>82</td>\n",
       "      <td>24</td>\n",
       "      <td>39</td>\n",
       "      <td>44</td>\n",
       "      <td>37</td>\n",
       "      <td>40</td>\n",
       "      <td>33</td>\n",
       "      <td>59</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>58</td>\n",
       "      <td>74</td>\n",
       "      <td>30</td>\n",
       "      <td>58</td>\n",
       "      <td>27</td>\n",
       "      <td>74</td>\n",
       "      <td>62</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>37</td>\n",
       "      <td>75</td>\n",
       "      <td>22</td>\n",
       "      <td>43</td>\n",
       "      <td>46</td>\n",
       "      <td>33</td>\n",
       "      <td>36</td>\n",
       "      <td>41</td>\n",
       "      <td>61</td>\n",
       "      <td>25</td>\n",
       "      <td>43</td>\n",
       "      <td>56</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>49</td>\n",
       "      <td>37</td>\n",
       "      <td>79</td>\n",
       "      <td>65</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AAPL  ABBV  AMZN  CVX  GOOGL  HD  JPM  LLY  MA  META  MRK  MSFT  NVDA  \\\n",
       "2018    27    80    14   43     31  30   45   30  45    11   39    58    69   \n",
       "2019    29    76    18   40     38  31   37   30  58    15   40    57    72   \n",
       "2020    29    81    21   42     40  26   37   29  62    14   39    58    74   \n",
       "2021    32    82    24   39     44  37   40   33  59    18   38    58    74   \n",
       "2022    37    75    22   43     46  33   36   41  61    25   43    56    72   \n",
       "\n",
       "      PFE  PG  TSLA  UNH   V  XOM  \n",
       "2018   27  52    13   76  53   35  \n",
       "2019   29  60    14   69  58   37  \n",
       "2020   31  60    15   70  63   36  \n",
       "2021   30  58    27   74  62   36  \n",
       "2022   35  49    37   79  65   37  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_esg_scores_df = pd.DataFrame.from_dict(historical_ESG_scores)\n",
    "historical_esg_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Industry: BTC Biotechnology': ['ABBV'],\n",
       " 'Industry: SEM Semiconductors & Semiconductor Equipment': ['NVDA'],\n",
       " 'Industry: DRG Pharmaceuticals': ['LLY', 'MRK', 'PFE'],\n",
       " 'Industry: OGX Oil & Gas Upstream & Integrated': ['CVX', 'XOM'],\n",
       " 'Industry: TSV IT services': ['MA', 'V'],\n",
       " 'Industry: IMS Interactive Media, Services & Home Entertainment': ['GOOGL',\n",
       "  'META'],\n",
       " 'Industry: SOF Software': ['MSFT'],\n",
       " 'Industry: THQ Computers & Peripherals and Office Electronics': ['AAPL'],\n",
       " 'Industry: AUT Automobiles': ['TSLA'],\n",
       " 'Industry: RTS Retailing': ['AMZN', 'HD'],\n",
       " 'Industry: HOU Household Products': ['PG'],\n",
       " 'Industry: BNK Banks': ['JPM'],\n",
       " 'Industry: HEA Health Care Providers & Services': ['UNH']}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "industries = set(company_data.values())\n",
    "industries_company_dict = {}\n",
    "for industry in industries:\n",
    "    industries_company_dict[industry] = [company for company in company_data.keys() if company_data[company] == industry]\n",
    "industries_company_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Company  Industry Best  Industry Mean\n",
      "Biodiversity                        15             77             10\n",
      "Business Ethics                     23            100             45\n",
      "Climate Strategy                    55             95             28\n",
      "Energy Mix                          47             91             26\n",
      "Human Rights                        11             93             17\n",
      "Occupational Health & Safety        38             95             40\n",
      "Operational Eco-Efficiency          24             97             31\n",
      "Risk & Crisis Management             8            100             24\n",
      "Social Impacts on Communities       52             93             17\n",
      "                               Company  Industry Best  Industry Mean\n",
      "Biodiversity                         8             77             10\n",
      "Business Ethics                     46            100             45\n",
      "Climate Strategy                    30             95             28\n",
      "Energy Mix                          46             91             26\n",
      "Human Rights                        24             93             17\n",
      "Occupational Health & Safety        66             95             40\n",
      "Operational Eco-Efficiency          37             97             31\n",
      "Risk & Crisis Management            10            100             24\n",
      "Social Impacts on Communities       45             93             17\n"
     ]
    }
   ],
   "source": [
    "lst = ['CVX', 'XOM']\n",
    "for company in lst:\n",
    "    print(performance_dict[company])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7 (v3.7.7:d7c567b08f, Mar 10 2020, 02:56:16) \n[Clang 6.0 (clang-600.0.57)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
